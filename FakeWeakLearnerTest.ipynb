{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PseudoBoosting import FakeEnsemble, FakeWeakLearner, FakeSchapireMulticlassBoosting, plot_fake_accuracies\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an ensemble of fake weak learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original link: https://colab.research.google.com/drive/10QVptDOsqZnh03WzwCL6LFuj_qjed9FA#scrollTo=ZdLhuBKM2MVj\n",
    "\n",
    "# train_y = np.array([])\n",
    "# train_loader_default = torch.utils.data.DataLoader(\n",
    "#     datasets.CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             ])),\n",
    "#         batch_size=100, shuffle=False)\n",
    "# for data in train_loader_default:\n",
    "#   train_y = np.concatenate((train_y, data[1]), axis = None)\n",
    "# ensemble = FakeEnsemble(wl, wlweights)\n",
    "# predictions, last_prediction = ensemble.schapirePredict(np.zeros((60000)), 10)\n",
    "# print((last_prediction == train_y).astype(int).sum()/len(last_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training 0th weak learning\n",
      "current accuracy: 0.18032683450059941\n",
      "Training 1th weak learning\n",
      "current accuracy: 0.18200797115202125\n",
      "Training 2th weak learning\n",
      "current accuracy: 0.1825063613231552\n",
      "Training 3th weak learning\n",
      "current accuracy: 0.1802678120262759\n",
      "Training 4th weak learning\n",
      "current accuracy: 0.18138816183658668\n"
     ]
    }
   ],
   "source": [
    "wl, weights = FakeSchapireMulticlassBoosting(FakeWeakLearner, 5, datasets.CIFAR10, advDelta=0, alphaTol=1e-10, adv=False, maxIt=5)\n",
    "# maxIt, adv, alphaTol and advDelta are meaningless here fyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00fa65877f95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m train_loader_default = torch.utils.data.DataLoader(\n\u001b[1;32m      3\u001b[0m     datasets.CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n\u001b[1;32m      4\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             ])),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "train_y = np.array([])\n",
    "train_loader_default = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=100, shuffle=False)\n",
    "for data in train_loader_default:\n",
    "  train_y = np.concatenate((train_y, data[1]), axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numWeakLearners: 5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f06dac91f868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_fake_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/AdversarialBoostingNeuralNets/PseudoBoosting.py\u001b[0m in \u001b[0;36mplot_fake_accuracies\u001b[0;34m(wl, wlweights, train_y)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numWeakLearners:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumWeakLearners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mcur_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cur_prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mcur_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_prediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mwl_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "predictions, last_prediction = plot_fake_accuracies(wl, weights, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
