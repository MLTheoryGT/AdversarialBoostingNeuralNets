{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PseudoBoosting import FakeEnsemble, FakeWeakLearner, FakeSchapireMulticlassBoosting, plot_fake_accuracies\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an ensemble of fake weak learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original link: https://colab.research.google.com/drive/10QVptDOsqZnh03WzwCL6LFuj_qjed9FA#scrollTo=ZdLhuBKM2MVj\n",
    "\n",
    "# train_y = np.array([])\n",
    "# train_loader_default = torch.utils.data.DataLoader(\n",
    "#     datasets.CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             ])),\n",
    "#         batch_size=100, shuffle=False)\n",
    "# for data in train_loader_default:\n",
    "#   train_y = np.concatenate((train_y, data[1]), axis = None)\n",
    "# ensemble = FakeEnsemble(wl, wlweights)\n",
    "# predictions, last_prediction = ensemble.schapirePredict(np.zeros((60000)), 10)\n",
    "# print((last_prediction == train_y).astype(int).sum()/len(last_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training 0th weak learning\n",
      "current accuracy: 0.18138666497895636\n",
      "Training 1th weak learning\n",
      "current accuracy: 0.1817374480636874\n",
      "Training 2th weak learning\n",
      "current accuracy: 0.1821144900477833\n",
      "Training 3th weak learning\n",
      "current accuracy: 0.18019495883150888\n",
      "Training 4th weak learning\n",
      "current accuracy: 0.17967982247582817\n",
      "Training 5th weak learning\n",
      "current accuracy: 0.18081835757979145\n",
      "Training 6th weak learning\n",
      "current accuracy: 0.1810344827586207\n",
      "Training 7th weak learning\n",
      "current accuracy: 0.18129246326433876\n",
      "Training 8th weak learning\n",
      "current accuracy: 0.18174362856421902\n",
      "Training 9th weak learning\n",
      "current accuracy: 0.18073593073593072\n",
      "Training 10th weak learning\n",
      "current accuracy: 0.1817119024297766\n",
      "Training 11th weak learning\n",
      "current accuracy: 0.1807836175743359\n",
      "Training 12th weak learning\n",
      "current accuracy: 0.18034502441808842\n",
      "Training 13th weak learning\n",
      "current accuracy: 0.1815824426032509\n",
      "Training 14th weak learning\n",
      "current accuracy: 0.18106017373660516\n",
      "Training 15th weak learning\n",
      "current accuracy: 0.18092167646501042\n",
      "Training 16th weak learning\n",
      "current accuracy: 0.1816026552868658\n",
      "Training 17th weak learning\n",
      "current accuracy: 0.18059999366426965\n",
      "Training 18th weak learning\n",
      "current accuracy: 0.1811965811965812\n",
      "Training 19th weak learning\n",
      "current accuracy: 0.18208652045577173\n",
      "Training 20th weak learning\n",
      "current accuracy: 0.1811965268280271\n",
      "Training 21th weak learning\n",
      "current accuracy: 0.18134288158686904\n",
      "Training 22th weak learning\n",
      "current accuracy: 0.18121680501224438\n",
      "Training 23th weak learning\n",
      "current accuracy: 0.1809575245417289\n",
      "Training 24th weak learning\n",
      "current accuracy: 0.1816042984770928\n",
      "Training 25th weak learning\n",
      "current accuracy: 0.18112017331464253\n",
      "Training 26th weak learning\n",
      "current accuracy: 0.18148924014473433\n",
      "Training 27th weak learning\n",
      "current accuracy: 0.1819368394244238\n",
      "Training 28th weak learning\n",
      "current accuracy: 0.18252050613594456\n",
      "Training 29th weak learning\n",
      "current accuracy: 0.18164788061597079\n",
      "Training 30th weak learning\n",
      "current accuracy: 0.18137425880711544\n",
      "Training 31th weak learning\n",
      "current accuracy: 0.1809169764560099\n",
      "Training 32th weak learning\n",
      "current accuracy: 0.18299034552845528\n",
      "Training 33th weak learning\n",
      "current accuracy: 0.18142479875274428\n",
      "Training 34th weak learning\n",
      "current accuracy: 0.18189041444190185\n",
      "Training 35th weak learning\n",
      "current accuracy: 0.1810517608882385\n",
      "Training 36th weak learning\n",
      "current accuracy: 0.17994400610842454\n",
      "Training 37th weak learning\n",
      "current accuracy: 0.18160384872718005\n",
      "Training 38th weak learning\n",
      "current accuracy: 0.18051229898938537\n",
      "Training 39th weak learning\n",
      "current accuracy: 0.18043726960722004\n",
      "Training 40th weak learning\n",
      "current accuracy: 0.18216979925840684\n",
      "Training 41th weak learning\n",
      "current accuracy: 0.18185012457675845\n",
      "Training 42th weak learning\n",
      "current accuracy: 0.1815606899624467\n",
      "Training 43th weak learning\n",
      "current accuracy: 0.18210250845726686\n",
      "Training 44th weak learning\n",
      "current accuracy: 0.18077364994255074\n",
      "Training 45th weak learning\n",
      "current accuracy: 0.1802336717104003\n",
      "Training 46th weak learning\n",
      "current accuracy: 0.18268622739344884\n",
      "Training 47th weak learning\n",
      "current accuracy: 0.18145174088297839\n",
      "Training 48th weak learning\n",
      "current accuracy: 0.18144092954958982\n",
      "Training 49th weak learning\n",
      "current accuracy: 0.1814962513957569\n",
      "Training 50th weak learning\n",
      "current accuracy: 0.18117116258380198\n",
      "Training 51th weak learning\n",
      "current accuracy: 0.18099949264332826\n",
      "Training 52th weak learning\n",
      "current accuracy: 0.1807974481658692\n",
      "Training 53th weak learning\n",
      "current accuracy: 0.18136180217964604\n",
      "Training 54th weak learning\n",
      "current accuracy: 0.18201824328634306\n",
      "Training 55th weak learning\n",
      "current accuracy: 0.18219948524038004\n",
      "Training 56th weak learning\n",
      "current accuracy: 0.18050817738387478\n",
      "Training 57th weak learning\n",
      "current accuracy: 0.18194276244502516\n",
      "Training 58th weak learning\n",
      "current accuracy: 0.18155305579591705\n",
      "Training 59th weak learning\n",
      "current accuracy: 0.18125419717949537\n",
      "Training 60th weak learning\n",
      "current accuracy: 0.18204178112821823\n",
      "Training 61th weak learning\n",
      "current accuracy: 0.18123844142592946\n",
      "Training 62th weak learning\n",
      "current accuracy: 0.18191394279877426\n",
      "Training 63th weak learning\n",
      "current accuracy: 0.18187326593743025\n",
      "Training 64th weak learning\n",
      "current accuracy: 0.18157458211050148\n",
      "Training 65th weak learning\n",
      "current accuracy: 0.18147224354054745\n",
      "Training 66th weak learning\n",
      "current accuracy: 0.18113255784226\n",
      "Training 67th weak learning\n",
      "current accuracy: 0.18188449462433795\n",
      "Training 68th weak learning\n",
      "current accuracy: 0.1805533445827629\n",
      "Training 69th weak learning\n",
      "current accuracy: 0.18088530545906498\n",
      "Training 70th weak learning\n",
      "current accuracy: 0.1801758745937679\n",
      "Training 71th weak learning\n",
      "current accuracy: 0.18207676819329477\n",
      "Training 72th weak learning\n",
      "current accuracy: 0.1818094659806334\n",
      "Training 73th weak learning\n",
      "current accuracy: 0.18193721457541595\n",
      "Training 74th weak learning\n",
      "current accuracy: 0.18169054532690895\n",
      "Training 75th weak learning\n",
      "current accuracy: 0.1805777465328817\n",
      "Training 76th weak learning\n",
      "current accuracy: 0.1813103913197008\n",
      "Training 77th weak learning\n",
      "current accuracy: 0.1813810348143874\n",
      "Training 78th weak learning\n",
      "current accuracy: 0.18029054292402913\n",
      "Training 79th weak learning\n",
      "current accuracy: 0.18145805379847932\n",
      "Training 80th weak learning\n",
      "current accuracy: 0.18051906440243512\n",
      "Training 81th weak learning\n",
      "current accuracy: 0.18059299191374664\n",
      "Training 82th weak learning\n",
      "current accuracy: 0.1813810348143874\n",
      "Training 83th weak learning\n",
      "current accuracy: 0.18130356914417295\n",
      "Training 84th weak learning\n",
      "current accuracy: 0.18119214631177732\n",
      "Training 85th weak learning\n",
      "current accuracy: 0.182004745719233\n",
      "Training 86th weak learning\n",
      "current accuracy: 0.18146804891356677\n",
      "Training 87th weak learning\n",
      "current accuracy: 0.181536\n",
      "Training 88th weak learning\n",
      "current accuracy: 0.18118344704457057\n",
      "Training 89th weak learning\n",
      "current accuracy: 0.1810289799565939\n",
      "Training 90th weak learning\n",
      "current accuracy: 0.181984292354544\n",
      "Training 91th weak learning\n",
      "current accuracy: 0.18033257795793303\n",
      "Training 92th weak learning\n",
      "current accuracy: 0.18088682567632464\n",
      "Training 93th weak learning\n",
      "current accuracy: 0.18042901441769765\n",
      "Training 94th weak learning\n",
      "current accuracy: 0.18042823257901147\n",
      "Training 95th weak learning\n",
      "current accuracy: 0.18053949903660887\n",
      "Training 96th weak learning\n",
      "current accuracy: 0.18039265680775116\n",
      "Training 97th weak learning\n",
      "current accuracy: 0.18137317635014077\n",
      "Training 98th weak learning\n",
      "current accuracy: 0.18198151950718686\n",
      "Training 99th weak learning\n",
      "current accuracy: 0.1808680644336487\n",
      "Training 100th weak learning\n",
      "current accuracy: 0.1812502002499119\n",
      "Training 101th weak learning\n",
      "current accuracy: 0.18171568469542249\n",
      "Training 102th weak learning\n",
      "current accuracy: 0.1806139141033454\n",
      "Training 103th weak learning\n",
      "current accuracy: 0.18232841565105837\n",
      "Training 104th weak learning\n",
      "current accuracy: 0.18147114490103616\n",
      "Training 105th weak learning\n",
      "current accuracy: 0.18128692319974454\n",
      "Training 106th weak learning\n",
      "current accuracy: 0.1816900506118265\n",
      "Training 107th weak learning\n",
      "current accuracy: 0.18209578913532626\n",
      "Training 108th weak learning\n",
      "current accuracy: 0.17996408414571574\n",
      "Training 109th weak learning\n",
      "current accuracy: 0.18237481566968006\n",
      "Training 110th weak learning\n",
      "current accuracy: 0.1818094104782427\n",
      "Training 111th weak learning\n",
      "current accuracy: 0.18049672699268388\n",
      "Training 112th weak learning\n",
      "current accuracy: 0.18104830948867645\n",
      "Training 113th weak learning\n",
      "current accuracy: 0.17964932451853982\n",
      "Training 114th weak learning\n",
      "current accuracy: 0.1812645011600928\n",
      "Training 115th weak learning\n",
      "current accuracy: 0.18306459399439992\n",
      "Training 116th weak learning\n",
      "current accuracy: 0.1810942717698433\n",
      "Training 117th weak learning\n",
      "current accuracy: 0.18120654855348733\n",
      "Training 118th weak learning\n",
      "current accuracy: 0.1799223587538901\n",
      "Training 119th weak learning\n",
      "current accuracy: 0.1812391430225825\n",
      "Training 120th weak learning\n",
      "current accuracy: 0.18058508924544106\n",
      "Training 121th weak learning\n",
      "current accuracy: 0.18136487134409462\n",
      "Training 122th weak learning\n",
      "current accuracy: 0.18062566311931325\n",
      "Training 123th weak learning\n",
      "current accuracy: 0.18155573376102646\n",
      "Training 124th weak learning\n",
      "current accuracy: 0.1805413032324269\n",
      "Training 125th weak learning\n",
      "current accuracy: 0.17960900131616964\n",
      "Training 126th weak learning\n",
      "current accuracy: 0.18157363819771352\n",
      "Training 127th weak learning\n",
      "current accuracy: 0.1813103913197008\n",
      "Training 128th weak learning\n",
      "current accuracy: 0.18045064652413265\n",
      "Training 129th weak learning\n",
      "current accuracy: 0.18044678392604957\n",
      "Training 130th weak learning\n",
      "current accuracy: 0.18131885780361673\n",
      "Training 131th weak learning\n",
      "current accuracy: 0.18166301687491948\n",
      "Training 132th weak learning\n",
      "current accuracy: 0.18201360369609856\n",
      "Training 133th weak learning\n",
      "current accuracy: 0.18086164308857025\n",
      "Training 134th weak learning\n",
      "current accuracy: 0.18103918610995218\n",
      "Training 135th weak learning\n",
      "current accuracy: 0.18221160056840202\n",
      "Training 136th weak learning\n",
      "current accuracy: 0.1806865575874238\n",
      "Training 137th weak learning\n",
      "current accuracy: 0.18120397054114634\n",
      "Training 138th weak learning\n",
      "current accuracy: 0.18235463904300697\n",
      "Training 139th weak learning\n",
      "current accuracy: 0.17989198171998338\n",
      "Training 140th weak learning\n",
      "current accuracy: 0.18103754398424637\n",
      "Training 141th weak learning\n",
      "current accuracy: 0.18064619836039222\n",
      "Training 142th weak learning\n",
      "current accuracy: 0.18100375686350062\n",
      "Training 143th weak learning\n",
      "current accuracy: 0.18151179585941263\n",
      "Training 144th weak learning\n",
      "current accuracy: 0.180313112804192\n",
      "Training 145th weak learning\n",
      "current accuracy: 0.18269323632617585\n",
      "Training 146th weak learning\n",
      "current accuracy: 0.17990249534928476\n",
      "Training 147th weak learning\n",
      "current accuracy: 0.1805918611030432\n",
      "Training 148th weak learning\n",
      "current accuracy: 0.1817918796412383\n",
      "Training 149th weak learning\n",
      "current accuracy: 0.18112451097675322\n",
      "Training 150th weak learning\n",
      "current accuracy: 0.18147600051473428\n",
      "Training 151th weak learning\n",
      "current accuracy: 0.18096129636205172\n",
      "Training 152th weak learning\n",
      "current accuracy: 0.18205889950917076\n",
      "Training 153th weak learning\n",
      "current accuracy: 0.18021815373725023\n",
      "Training 154th weak learning\n",
      "current accuracy: 0.18150419625564881\n",
      "Training 155th weak learning\n",
      "current accuracy: 0.18227872608176568\n",
      "Training 156th weak learning\n",
      "current accuracy: 0.18127695179249534\n",
      "Training 157th weak learning\n",
      "current accuracy: 0.1806772972798137\n",
      "Training 158th weak learning\n",
      "current accuracy: 0.1820555806306016\n",
      "Training 159th weak learning\n",
      "current accuracy: 0.1816255778120185\n",
      "Training 160th weak learning\n",
      "current accuracy: 0.18084315942497173\n",
      "Training 161th weak learning\n",
      "current accuracy: 0.1814800439873213\n",
      "Training 162th weak learning\n",
      "current accuracy: 0.1803816818459756\n",
      "Training 163th weak learning\n",
      "current accuracy: 0.1818035582151015\n",
      "Training 164th weak learning\n",
      "current accuracy: 0.1820733714064466\n",
      "Training 165th weak learning\n",
      "current accuracy: 0.18272510780716997\n",
      "Training 166th weak learning\n",
      "current accuracy: 0.181132561962162\n",
      "Training 167th weak learning\n",
      "current accuracy: 0.18072056408770404\n",
      "Training 168th weak learning\n",
      "current accuracy: 0.18070000321988602\n",
      "Training 169th weak learning\n",
      "current accuracy: 0.18151049221545304\n",
      "Training 170th weak learning\n",
      "current accuracy: 0.18121173058330647\n",
      "Training 171th weak learning\n",
      "current accuracy: 0.18140721366527818\n",
      "Training 172th weak learning\n",
      "current accuracy: 0.1830295208904662\n",
      "Training 173th weak learning\n",
      "current accuracy: 0.18090370993304655\n",
      "Training 174th weak learning\n",
      "current accuracy: 0.180518435034616\n",
      "Training 175th weak learning\n",
      "current accuracy: 0.18191462003343192\n",
      "Training 176th weak learning\n",
      "current accuracy: 0.18156693874927696\n",
      "Training 177th weak learning\n",
      "current accuracy: 0.18296825961756236\n",
      "Training 178th weak learning\n",
      "current accuracy: 0.18198831918944208\n",
      "Training 179th weak learning\n",
      "current accuracy: 0.1809462296140804\n",
      "Training 180th weak learning\n",
      "current accuracy: 0.17991280477958985\n",
      "Training 181th weak learning\n",
      "current accuracy: 0.1816220046379799\n",
      "Training 182th weak learning\n",
      "current accuracy: 0.18134748559963756\n",
      "Training 183th weak learning\n",
      "current accuracy: 0.18114817688130333\n",
      "Training 184th weak learning\n",
      "current accuracy: 0.18221720187187349\n",
      "Training 185th weak learning\n",
      "current accuracy: 0.18172999191592562\n",
      "Training 186th weak learning\n",
      "current accuracy: 0.18127612689976993\n",
      "Training 187th weak learning\n",
      "current accuracy: 0.1808661926308985\n",
      "Training 188th weak learning\n",
      "current accuracy: 0.1814808840135506\n",
      "Training 189th weak learning\n",
      "current accuracy: 0.18152250917756166\n",
      "Training 190th weak learning\n",
      "current accuracy: 0.18174438238732302\n",
      "Training 191th weak learning\n",
      "current accuracy: 0.18038975285539136\n",
      "Training 192th weak learning\n",
      "current accuracy: 0.1815057389274366\n",
      "Training 193th weak learning\n",
      "current accuracy: 0.18222078551802165\n",
      "Training 194th weak learning\n",
      "current accuracy: 0.1811112545172948\n",
      "Training 195th weak learning\n",
      "current accuracy: 0.18098298922217892\n",
      "Training 196th weak learning\n",
      "current accuracy: 0.1814586147019101\n",
      "Training 197th weak learning\n",
      "current accuracy: 0.1811089619600258\n",
      "Training 198th weak learning\n",
      "current accuracy: 0.18174762305154907\n",
      "Training 199th weak learning\n",
      "current accuracy: 0.18123426505712995\n",
      "Training 200th weak learning\n",
      "current accuracy: 0.179630106972548\n",
      "Training 201th weak learning\n",
      "current accuracy: 0.18154492566257271\n",
      "Training 202th weak learning\n",
      "current accuracy: 0.18137984596466247\n",
      "Training 203th weak learning\n",
      "current accuracy: 0.18204464574571336\n",
      "Training 204th weak learning\n",
      "current accuracy: 0.18174480175642516\n",
      "Training 205th weak learning\n",
      "current accuracy: 0.18035280789771807\n",
      "Training 206th weak learning\n",
      "current accuracy: 0.1806759238377525\n",
      "Training 207th weak learning\n",
      "current accuracy: 0.1807894992079144\n",
      "Training 208th weak learning\n",
      "current accuracy: 0.18218715501006558\n",
      "Training 209th weak learning\n",
      "current accuracy: 0.18162441466171483\n",
      "Training 210th weak learning\n",
      "current accuracy: 0.18140332707618617\n",
      "Training 211th weak learning\n",
      "current accuracy: 0.1825029905273027\n",
      "Training 212th weak learning\n",
      "current accuracy: 0.18151761693300056\n",
      "Training 213th weak learning\n",
      "current accuracy: 0.18141350279023258\n",
      "Training 214th weak learning\n",
      "current accuracy: 0.1823634300534933\n",
      "Training 215th weak learning\n",
      "current accuracy: 0.18174767321613236\n",
      "Training 216th weak learning\n",
      "current accuracy: 0.18041487330507103\n",
      "Training 217th weak learning\n",
      "current accuracy: 0.18100794036622914\n",
      "Training 218th weak learning\n",
      "current accuracy: 0.18173267166163926\n",
      "Training 219th weak learning\n",
      "current accuracy: 0.18066396761133605\n",
      "Training 220th weak learning\n",
      "current accuracy: 0.18135954983506888\n",
      "Training 221th weak learning\n",
      "current accuracy: 0.1814685540689031\n",
      "Training 222th weak learning\n",
      "current accuracy: 0.18127025275437458\n",
      "Training 223th weak learning\n",
      "current accuracy: 0.18144129554655872\n",
      "Training 224th weak learning\n",
      "current accuracy: 0.18215289216161223\n",
      "Training 225th weak learning\n",
      "current accuracy: 0.1818711368564124\n",
      "Training 226th weak learning\n",
      "current accuracy: 0.18202742568158978\n",
      "Training 227th weak learning\n",
      "current accuracy: 0.1815943765993975\n",
      "Training 228th weak learning\n",
      "current accuracy: 0.18144102680452467\n",
      "Training 229th weak learning\n",
      "current accuracy: 0.18113709337398243\n",
      "Training 230th weak learning\n",
      "current accuracy: 0.18036893646094285\n",
      "Training 231th weak learning\n",
      "current accuracy: 0.18070067609096496\n",
      "Training 232th weak learning\n",
      "current accuracy: 0.18177395816442354\n",
      "Training 233th weak learning\n",
      "current accuracy: 0.18112475759534583\n",
      "Training 234th weak learning\n",
      "current accuracy: 0.18201818240641884\n",
      "Training 235th weak learning\n",
      "current accuracy: 0.18167390036924272\n",
      "Training 236th weak learning\n",
      "current accuracy: 0.1816062176165803\n",
      "Training 237th weak learning\n",
      "current accuracy: 0.1810188189487346\n",
      "Training 238th weak learning\n",
      "current accuracy: 0.18113830613830614\n",
      "Training 239th weak learning\n",
      "current accuracy: 0.1819150653964153\n",
      "Training 240th weak learning\n",
      "current accuracy: 0.18063055780113177\n",
      "Training 241th weak learning\n",
      "current accuracy: 0.18131564400221117\n",
      "Training 242th weak learning\n",
      "current accuracy: 0.18032786885245902\n",
      "Training 243th weak learning\n",
      "current accuracy: 0.18170011039677902\n",
      "Training 244th weak learning\n",
      "current accuracy: 0.18145592380211878\n",
      "Training 245th weak learning\n",
      "current accuracy: 0.1819181982914833\n",
      "Training 246th weak learning\n",
      "current accuracy: 0.18086866262285511\n",
      "Training 247th weak learning\n",
      "current accuracy: 0.1808382844712834\n",
      "Training 248th weak learning\n",
      "current accuracy: 0.18208984311560075\n",
      "Training 249th weak learning\n",
      "current accuracy: 0.18174446138376205\n",
      "Training 250th weak learning\n",
      "current accuracy: 0.18142639577460226\n",
      "Training 251th weak learning\n",
      "current accuracy: 0.18169398907103826\n",
      "Training 252th weak learning\n",
      "current accuracy: 0.18221702252120503\n",
      "Training 253th weak learning\n",
      "current accuracy: 0.1820428603947839\n",
      "Training 254th weak learning\n",
      "current accuracy: 0.18066314458885685\n",
      "Training 255th weak learning\n",
      "current accuracy: 0.18084693084693085\n",
      "Training 256th weak learning\n",
      "current accuracy: 0.18176178660049627\n",
      "Training 257th weak learning\n",
      "current accuracy: 0.1802768502609654\n",
      "Training 258th weak learning\n",
      "current accuracy: 0.1810439383186012\n",
      "Training 259th weak learning\n",
      "current accuracy: 0.18116176661054267\n",
      "Training 260th weak learning\n",
      "current accuracy: 0.1803299902944031\n",
      "Training 261th weak learning\n",
      "current accuracy: 0.18200442247658688\n",
      "Training 262th weak learning\n",
      "current accuracy: 0.18249238940345877\n",
      "Training 263th weak learning\n",
      "current accuracy: 0.18200382483549965\n",
      "Training 264th weak learning\n",
      "current accuracy: 0.18122284899176555\n",
      "Training 265th weak learning\n",
      "current accuracy: 0.1810565964217294\n",
      "Training 266th weak learning\n",
      "current accuracy: 0.18156652011073116\n",
      "Training 267th weak learning\n",
      "current accuracy: 0.1824727555786196\n",
      "Training 268th weak learning\n",
      "current accuracy: 0.18022954221242382\n",
      "Training 269th weak learning\n",
      "current accuracy: 0.18089964053240065\n",
      "Training 270th weak learning\n",
      "current accuracy: 0.1823777129899579\n",
      "Training 271th weak learning\n",
      "current accuracy: 0.18126868581827635\n",
      "Training 272th weak learning\n",
      "current accuracy: 0.18051278726783573\n",
      "Training 273th weak learning\n",
      "current accuracy: 0.18102497567304573\n",
      "Training 274th weak learning\n",
      "current accuracy: 0.18113918295771902\n",
      "Training 275th weak learning\n",
      "current accuracy: 0.17906765355148682\n",
      "Training 276th weak learning\n",
      "current accuracy: 0.18231217258321675\n",
      "Training 277th weak learning\n",
      "current accuracy: 0.18246706897670495\n",
      "Training 278th weak learning\n",
      "current accuracy: 0.18096010379500488\n",
      "Training 279th weak learning\n",
      "current accuracy: 0.18053843658773921\n",
      "Training 280th weak learning\n",
      "current accuracy: 0.18230536880054565\n",
      "Training 281th weak learning\n",
      "current accuracy: 0.1806223203845654\n",
      "Training 282th weak learning\n",
      "current accuracy: 0.18023350352857004\n",
      "Training 283th weak learning\n",
      "current accuracy: 0.18185948401752394\n",
      "Training 284th weak learning\n",
      "current accuracy: 0.1815255559890753\n",
      "Training 285th weak learning\n",
      "current accuracy: 0.18109752151685757\n",
      "Training 286th weak learning\n",
      "current accuracy: 0.18058478774730435\n",
      "Training 287th weak learning\n",
      "current accuracy: 0.18256589599119227\n",
      "Training 288th weak learning\n",
      "current accuracy: 0.18105885794143456\n",
      "Training 289th weak learning\n",
      "current accuracy: 0.18239342444306728\n",
      "Training 290th weak learning\n",
      "current accuracy: 0.1820310213637694\n",
      "Training 291th weak learning\n",
      "current accuracy: 0.18036797807790175\n",
      "Training 292th weak learning\n",
      "current accuracy: 0.18100533229288593\n",
      "Training 293th weak learning\n",
      "current accuracy: 0.18209423058086002\n",
      "Training 294th weak learning\n",
      "current accuracy: 0.18023520239100774\n",
      "Training 295th weak learning\n",
      "current accuracy: 0.18063211455037673\n",
      "Training 296th weak learning\n",
      "current accuracy: 0.18099208546396117\n",
      "Training 297th weak learning\n",
      "current accuracy: 0.1818063338980842\n",
      "Training 298th weak learning\n",
      "current accuracy: 0.1819870311838118\n",
      "Training 299th weak learning\n",
      "current accuracy: 0.18139006170834687\n",
      "Training 300th weak learning\n",
      "current accuracy: 0.1810565964217294\n",
      "Training 301th weak learning\n",
      "current accuracy: 0.18111747105502796\n",
      "Training 302th weak learning\n",
      "current accuracy: 0.18053380318454712\n",
      "Training 303th weak learning\n",
      "current accuracy: 0.18249079234705518\n",
      "Training 304th weak learning\n",
      "current accuracy: 0.18268291093882338\n",
      "Training 305th weak learning\n",
      "current accuracy: 0.18215226511431265\n",
      "Training 306th weak learning\n",
      "current accuracy: 0.18225209429183714\n",
      "Training 307th weak learning\n",
      "current accuracy: 0.18150829464662532\n",
      "Training 308th weak learning\n",
      "current accuracy: 0.18270421800638895\n",
      "Training 309th weak learning\n",
      "current accuracy: 0.18060799375081368\n",
      "Training 310th weak learning\n",
      "current accuracy: 0.18140944189228814\n",
      "Training 311th weak learning\n",
      "current accuracy: 0.18174136306022295\n",
      "Training 312th weak learning\n",
      "current accuracy: 0.1807858278446514\n",
      "Training 313th weak learning\n",
      "current accuracy: 0.18041169956354636\n",
      "Training 314th weak learning\n",
      "current accuracy: 0.18095238095238095\n",
      "Training 315th weak learning\n",
      "current accuracy: 0.18144102680452467\n",
      "Training 316th weak learning\n",
      "current accuracy: 0.1804858985214616\n",
      "Training 317th weak learning\n",
      "current accuracy: 0.18141119221411192\n",
      "Training 318th weak learning\n",
      "current accuracy: 0.1827277171256314\n",
      "Training 319th weak learning\n",
      "current accuracy: 0.18114614680099436\n",
      "Training 320th weak learning\n",
      "current accuracy: 0.18073427370752843\n",
      "Training 321th weak learning\n",
      "current accuracy: 0.18231017507253935\n",
      "Training 322th weak learning\n",
      "current accuracy: 0.1822909894682096\n",
      "Training 323th weak learning\n",
      "current accuracy: 0.18108927349173756\n",
      "Training 324th weak learning\n",
      "current accuracy: 0.18149814199100334\n",
      "Training 325th weak learning\n",
      "current accuracy: 0.1817032860198328\n",
      "Training 326th weak learning\n",
      "current accuracy: 0.18192201011584272\n",
      "Training 327th weak learning\n",
      "current accuracy: 0.18055283916813353\n",
      "Training 328th weak learning\n",
      "current accuracy: 0.1812073970190144\n",
      "Training 329th weak learning\n",
      "current accuracy: 0.18038717246773564\n",
      "Training 330th weak learning\n",
      "current accuracy: 0.18044059180082123\n",
      "Training 331th weak learning\n",
      "current accuracy: 0.18222554144884243\n",
      "Training 332th weak learning\n",
      "current accuracy: 0.18082583411844969\n",
      "Training 333th weak learning\n",
      "current accuracy: 0.18101847326752027\n",
      "Training 334th weak learning\n",
      "current accuracy: 0.18207667418374351\n",
      "Training 335th weak learning\n",
      "current accuracy: 0.18173842404549148\n",
      "Training 336th weak learning\n",
      "current accuracy: 0.18126054783850448\n",
      "Training 337th weak learning\n",
      "current accuracy: 0.18055826030509575\n",
      "Training 338th weak learning\n",
      "current accuracy: 0.18183303915800483\n",
      "Training 339th weak learning\n",
      "current accuracy: 0.18110184731077325\n",
      "Training 340th weak learning\n",
      "current accuracy: 0.180881827338597\n",
      "Training 341th weak learning\n",
      "current accuracy: 0.18199076953291218\n",
      "Training 342th weak learning\n",
      "current accuracy: 0.18248508362948715\n",
      "Training 343th weak learning\n",
      "current accuracy: 0.17978840786655417\n",
      "Training 344th weak learning\n",
      "current accuracy: 0.18232458140595478\n",
      "Training 345th weak learning\n",
      "current accuracy: 0.1815079623009425\n",
      "Training 346th weak learning\n",
      "current accuracy: 0.18260756022719854\n",
      "Training 347th weak learning\n",
      "current accuracy: 0.18168747140709757\n",
      "Training 348th weak learning\n",
      "current accuracy: 0.18093322084496075\n",
      "Training 349th weak learning\n",
      "current accuracy: 0.18139960160663554\n",
      "Training 350th weak learning\n",
      "current accuracy: 0.18163118714901397\n",
      "Training 351th weak learning\n",
      "current accuracy: 0.18084552845528457\n",
      "Training 352th weak learning\n",
      "current accuracy: 0.18061084643999217\n",
      "Training 353th weak learning\n",
      "current accuracy: 0.1823802669458257\n",
      "Training 354th weak learning\n",
      "current accuracy: 0.18265375965581304\n",
      "Training 355th weak learning\n",
      "current accuracy: 0.18195121951219512\n",
      "Training 356th weak learning\n",
      "current accuracy: 0.17996742671009772\n",
      "Training 357th weak learning\n",
      "current accuracy: 0.1809619694066448\n",
      "Training 358th weak learning\n",
      "current accuracy: 0.18198415544615787\n",
      "Training 359th weak learning\n",
      "current accuracy: 0.1814529300320115\n",
      "Training 360th weak learning\n",
      "current accuracy: 0.1816824129086718\n",
      "Training 361th weak learning\n",
      "current accuracy: 0.18155713633100568\n",
      "Training 362th weak learning\n",
      "current accuracy: 0.17993158494868872\n",
      "Training 363th weak learning\n",
      "current accuracy: 0.18132425621051942\n",
      "Training 364th weak learning\n",
      "current accuracy: 0.18120041617895696\n",
      "Training 365th weak learning\n",
      "current accuracy: 0.18102915840457692\n",
      "Training 366th weak learning\n",
      "current accuracy: 0.18237597911227155\n",
      "Training 367th weak learning\n",
      "current accuracy: 0.1821032005225343\n",
      "Training 368th weak learning\n",
      "current accuracy: 0.18231719270731228\n",
      "Training 369th weak learning\n",
      "current accuracy: 0.1809867234879528\n",
      "Training 370th weak learning\n",
      "current accuracy: 0.18081469180423954\n",
      "Training 371th weak learning\n",
      "current accuracy: 0.18164897959183673\n",
      "Training 372th weak learning\n",
      "current accuracy: 0.1813658089438879\n",
      "Training 373th weak learning\n",
      "current accuracy: 0.18107843137254903\n",
      "Training 374th weak learning\n",
      "current accuracy: 0.18170229456756226\n",
      "Training 375th weak learning\n",
      "current accuracy: 0.18222921171613918\n",
      "Training 376th weak learning\n",
      "current accuracy: 0.1807213200286963\n",
      "Training 377th weak learning\n",
      "current accuracy: 0.18000519682993374\n",
      "Training 378th weak learning\n",
      "current accuracy: 0.1811478351659108\n",
      "Training 379th weak learning\n",
      "current accuracy: 0.18027266485761925\n",
      "Training 380th weak learning\n",
      "current accuracy: 0.1796882658562886\n",
      "Training 381th weak learning\n"
     ]
    }
   ],
   "source": [
    "wl, weights = FakeSchapireMulticlassBoosting(FakeWeakLearner, 500, datasets.CIFAR10, advDelta=0, alphaTol=1e-10, adv=False, maxIt=5)\n",
    "# maxIt, adv, alphaTol and advDelta are meaningless here fyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array([])\n",
    "train_loader_default = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=100, shuffle=False)\n",
    "for data in train_loader_default:\n",
    "  train_y = np.concatenate((train_y, data[1]), axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, last_prediction = plot_fake_accuracies(wl, weights, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
